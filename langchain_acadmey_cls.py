# -*- coding: utf-8 -*-
"""Langchain_acadmey_cls.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s5zvmxyAGz7VX6Osl9-8fRFAbfh9LjjS

#Understanding of Chain, Nodes and  Edges With LLM Integration And Tools Calling
"""

!pip install -q -U langgraph langchain_google_genai langchain_core

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from pprint import pprint
messages = [HumanMessage(content="Hi I am Muneeb",name="Muneeb")]
messages.extend([AIMessage(content="Hi Muneeb, How can i Assist You",name="AI")])
messages.extend([HumanMessage(content="What is the capital of Pakistan",name="Muneeb")])
for m in messages:
  m.pretty_print()

# Creating LLM
from langchain_google_genai import ChatGoogleGenerativeAI
from google.colab import userdata
GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')
llm = ChatGoogleGenerativeAI(
    api_key=GEMINI_API_KEY,
    model="gemini-2.0-flash",
    temperature=0,
)
result = llm.invoke(messages)
result.content

# Creating Tools
from langchain_core.messages import HumanMessage
def multiply(a:int,b:int) -> int:
  """Multiply a and b
  Args:
  a: first int
  b: second int
  return: a*b
  """
  return a*b
# def add(a:int,b:int) -> int:
#   """Add a and b
#   Args
#   a: first int
#   b: second int
#   return: a+b
#   """
#   return a+b
llm_with_tools = llm.bind_tools([multiply])
result = llm_with_tools.invoke([HumanMessage(content="What is 2 + 2",name="Muneeb")])
result

from IPython.display import display, Image
from langgraph.graph import END,START,StateGraph, MessagesState,add_messages
from typing import TypedDict,Annotated
from langchain_core.messages import AnyMessage
class MessageState(TypedDict):
  messages:Annotated[list[AnyMessage],add_messages]
def tool_calling_llm(state:MessageState):
  return {"messages":[llm_with_tools.invoke(state["messages"])]}
builder = StateGraph(MessageState)
builder.add_node("llm_with_tools",tool_calling_llm)
builder.add_edge(START,"llm_with_tools")
builder.add_edge("llm_with_tools",END)
graph = builder.compile()
display(Image(graph.get_graph().draw_mermaid_png()))

messages = graph.invoke({"messages":[HumanMessage(content="What is 2 + 2")]})
for m in messages["messages"]:
  m.pretty_print()

messages = graph.invoke({"messages":[HumanMessage(content="Where is Karachi")]})
for m in messages["messages"]:
  m.pretty_print()

"""Well it take too much time for me  to understand &

Here Our each question aur query which we ask from LLM pass through tool_call  node

"""

