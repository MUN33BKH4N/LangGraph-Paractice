{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GSbXQTDYLY-",
        "outputId": "c660a9c6-b0c7-4f96-97f6-550cbd8dc34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U langchain_core langgraph langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVtolBZqYX7F",
        "outputId": "2aec0e09-7912-42a8-ea60-48dec9a41696"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3e5c2a65-59cf-4cde-a26c-5deeca03cfab-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "llm.invoke(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bXuF4FTuZPPT"
      },
      "outputs": [],
      "source": [
        "def multiply(a,b):\n",
        "  \"\"\"Multiply a and b\n",
        "  return a *b\n",
        "  \"\"\"\n",
        "  return a * b\n",
        "def add(a,b):\n",
        "  \"\"\"Add a and b\n",
        "  return a + b\n",
        "  \"\"\"\n",
        "  return a + b\n",
        "def subtract(a,b):\n",
        "  \"\"\"Subtract a and b\n",
        "  return a - b\n",
        "  \"\"\"\n",
        "  return a - b\n",
        "def divide(a,b):\n",
        "  \"\"\"Divide a and b\n",
        "  return a / b\n",
        "  \"\"\"\n",
        "  return a / b\n",
        "tools = [multiply,add,subtract,divide]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dihJXRtKb-8j"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage,HumanMessage\n",
        "from langgraph.graph.message import MessagesState\n",
        "system_message = SystemMessage(content=\"You are a helpful assistant. which do only arthematic operation on provided input\")\n",
        "def assistant(state:MessagesState):\n",
        "  return {\"messages\":[llm_with_tools.invoke([system_message] + state[\"messages\"])]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ui181snKck10"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START,StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.prebuilt import ToolNode\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"assistant\",assistant)\n",
        "builder.add_node(\"tools\",ToolNode(tools))\n",
        "builder.add_edge(START,\"assistant\")\n",
        "builder.add_conditional_edges(\"assistant\",tools_condition)\n",
        "builder.add_edge(\"tools\",\"assistant\")\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE3jXpGMgODx",
        "outputId": "a8e37183-a25a-4b9e-a873-50c42beba932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "what is 2 + 2 -2 /1*12\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (910a5ce6-4173-4670-853f-d11d40a328e0)\n",
            " Call ID: 910a5ce6-4173-4670-853f-d11d40a328e0\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 2.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "4.0\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  subtract (778874fc-c97a-43a3-b78b-03fc70775888)\n",
            " Call ID: 778874fc-c97a-43a3-b78b-03fc70775888\n",
            "  Args:\n",
            "    a: 4.0\n",
            "    b: 2.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: subtract\n",
            "\n",
            "2.0\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  divide (12561b74-a495-41a3-a675-1a7809ceec20)\n",
            " Call ID: 12561b74-a495-41a3-a675-1a7809ceec20\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 1.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: divide\n",
            "\n",
            "2.0\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (66837258-f84f-45fb-8c2a-341297113eb8)\n",
            " Call ID: 66837258-f84f-45fb-8c2a-341297113eb8\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 12.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "24.0\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "2 + 2 -2 /1*12 = -20.0\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\":[HumanMessage(content=\"what is 2 + 2 -2 /1*12\")]})\n",
        "from pprint import pprint\n",
        "for m in messages[\"messages\"]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mo3Nq2GkgqVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4f06bb-290b-4d8d-b91e-512b75d66b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "what is 2 + 2\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (d066c0b1-de70-4c9a-9bae-2aeec11de45e)\n",
            " Call ID: d066c0b1-de70-4c9a-9bae-2aeec11de45e\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 2.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "4.0\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "2 + 2 = 4\n"
          ]
        }
      ],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory = MemorySaver()\n",
        "graph_memory = builder.compile(checkpointer=memory)\n",
        "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
        "messages = [HumanMessage(content=\"what is 2 + 2\")]\n",
        "messages = graph_memory.invoke({\"messages\":messages},config=config)\n",
        "from pprint import pprint\n",
        "for m in messages[\"messages\"]:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_memory.invoke({\"messages\":[HumanMessage(content=\"No add 10\")]},config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOq9pdU7LDJv",
        "outputId": "3f35e848-c739-4413-ec7a-cfd2ff7f319b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is 2 + 2', additional_kwargs={}, response_metadata={}, id='2e1f240f-365d-4744-be33-a3c112e93394'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 2.0, \"b\": 2.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--b9e5084e-5211-4562-b497-61c36401de28-0', tool_calls=[{'name': 'add', 'args': {'a': 2.0, 'b': 2.0}, 'id': 'd066c0b1-de70-4c9a-9bae-2aeec11de45e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 83, 'output_tokens': 5, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='4.0', name='add', id='481782fc-74f3-4c32-80c3-2ee023769a17', tool_call_id='d066c0b1-de70-4c9a-9bae-2aeec11de45e'),\n",
              "  AIMessage(content='2 + 2 = 4', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ab60460f-badc-48ab-b12e-a400520d70d3-0', usage_metadata={'input_tokens': 91, 'output_tokens': 8, 'total_tokens': 99, 'input_token_details': {'cache_read': 0}}),\n",
              "  HumanMessage(content='No add 10', additional_kwargs={}, response_metadata={}, id='5f55537d-4a45-4de5-a6e1-96df83eb4468'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 4.0, \"b\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--45e23793-6fa7-477a-8eae-4c1b574914de-0', tool_calls=[{'name': 'add', 'args': {'a': 4.0, 'b': 10.0}, 'id': 'a167ef7e-b408-44e4-8846-0cd12fd6cc9e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 5, 'total_tokens': 108, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='14.0', name='add', id='242828fb-f86d-474e-9eca-60420595a15a', tool_call_id='a167ef7e-b408-44e4-8846-0cd12fd6cc9e'),\n",
              "  AIMessage(content='4 + 10 = 14', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f10254dc-eec7-46cb-bec9-7b9f4eeb1d49-0', usage_metadata={'input_tokens': 111, 'output_tokens': 10, 'total_tokens': 121, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a8_MFQWCLKF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}